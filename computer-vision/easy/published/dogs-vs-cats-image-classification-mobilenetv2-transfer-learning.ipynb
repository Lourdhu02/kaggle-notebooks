{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Image Classification using MobileNetV2 Transfer Learning\n",
    "\n",
    "**A complete beginner-friendly guide to binary image classification with deep learning**\n",
    "\n",
    "In this notebook we will:\n",
    "- Load the Kaggle Dogs vs Cats dataset\n",
    "- Understand what Transfer Learning is and why MobileNetV2\n",
    "- Build, train and fine-tune a classifier\n",
    "- Visualize predictions, training progress and model behaviour\n",
    "- Evaluate with real metrics\n",
    "\n",
    "**No prior deep learning experience needed. Every step is explained.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Binary Image Classification?\n",
    "\n",
    "Binary classification means the model must choose between exactly **two classes**.\n",
    "\n",
    "In our case:\n",
    "- Input → a photo of an animal\n",
    "- Output → **Dog** (1) or **Cat** (0)\n",
    "\n",
    "The model learns by looking at thousands of labelled photos and adjusting its internal weights until it gets good at telling them apart.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What is Transfer Learning?\n",
    "\n",
    "Training a deep neural network from scratch needs:\n",
    "- Millions of images\n",
    "- Days of GPU time\n",
    "- A lot of expertise\n",
    "\n",
    "**Transfer Learning lets us skip all that.**\n",
    "\n",
    "We take a model already trained on 1.2 million images (ImageNet) and reuse its knowledge. The model already knows how to detect edges, textures, shapes and object parts. We only need to teach it the final step: *is this a dog or a cat?*\n",
    "\n",
    "```\n",
    "Pretrained MobileNetV2          Our Addition\n",
    "─────────────────────    +    ──────────────────\n",
    "Knows edges, textures         New Dense layers\n",
    "Knows shapes, patterns   →    Trained on our data\n",
    "Knows animal features         Outputs: Dog or Cat\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why MobileNetV2?\n",
    "\n",
    "| Property | Value |\n",
    "|---|---|\n",
    "| Parameters | 3.4 Million (very light) |\n",
    "| Input size | 224 x 224 pixels |\n",
    "| Designed for | Mobile and edge devices |\n",
    "| Speed | Very fast — ideal for Kaggle |\n",
    "| Accuracy | Good — 71.8% on ImageNet |\n",
    "\n",
    "It uses **depthwise separable convolutions** — a smart technique that gets similar accuracy to larger models while being much cheaper to run.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f'TensorFlow version : {tf.__version__}')\n",
    "print(f'GPU available      : {len(tf.config.list_physical_devices(\"GPU\")) > 0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the Dataset\n",
    "\n",
    "We use `kagglehub` to download the Dogs vs Cats dataset directly. The dataset contains 25,000 images — 12,500 dogs and 12,500 cats — perfectly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download('salader/dogs-vs-cats')\n",
    "print(f'Dataset downloaded to: {path}')\n",
    "\n",
    "# Explore the folder structure\n",
    "for root, dirs, files in os.walk(path):\n",
    "    level = root.replace(path, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    if level < 2:\n",
    "        for f in files[:3]:\n",
    "            print(f'{indent}  {f}')\n",
    "        if len(files) > 3:\n",
    "            print(f'{indent}  ... ({len(files)} total files)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory paths\n",
    "# Adjust these paths based on the actual folder structure printed above\n",
    "BASE_DIR  = path\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR  = os.path.join(BASE_DIR, 'test')\n",
    "\n",
    "# If the structure is flat (all images in one folder), use this instead:\n",
    "# TRAIN_DIR = os.path.join(BASE_DIR, 'train', 'train')\n",
    "\n",
    "# Count images per class\n",
    "for split_name, split_dir in [('Train', TRAIN_DIR), ('Test', TEST_DIR)]:\n",
    "    if os.path.exists(split_dir):\n",
    "        for cls in ['cats', 'dogs', 'cat', 'dog']:\n",
    "            cls_path = os.path.join(split_dir, cls)\n",
    "            if os.path.exists(cls_path):\n",
    "                print(f'{split_name} | {cls}: {len(os.listdir(cls_path))} images')\n",
    "\n",
    "# Config\n",
    "IMG_SIZE   = 224   # MobileNetV2 expects 224x224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_1   = 10    # Phase 1: frozen base\n",
    "EPOCHS_2   = 5     # Phase 2: fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Raw Images\n",
    "\n",
    "Always look at your data before training. This tells you image quality, variety, and potential problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def show_sample_images(train_dir, n_each=4):\n",
    "    fig, axes = plt.subplots(2, n_each, figsize=(14, 6))\n",
    "    classes = ['cats', 'dogs']\n",
    "    # Try alternate naming\n",
    "    alt = ['cat', 'dog']\n",
    "\n",
    "    for row, (cls, alt_cls) in enumerate(zip(classes, alt)):\n",
    "        cls_dir = os.path.join(train_dir, cls)\n",
    "        if not os.path.exists(cls_dir):\n",
    "            cls_dir = os.path.join(train_dir, alt_cls)\n",
    "        files = random.sample(os.listdir(cls_dir), min(n_each, len(os.listdir(cls_dir))))\n",
    "        for col, fname in enumerate(files):\n",
    "            img = load_img(os.path.join(cls_dir, fname), target_size=(224, 224))\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "            axes[row, col].set_title(cls.capitalize(), fontsize=11, fontweight='bold')\n",
    "\n",
    "    plt.suptitle('Sample Images from Dataset', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation — Teaching the Model to Generalise\n",
    "\n",
    "Augmentation means we artificially create variations of each image during training — flips, zooms, rotations. This prevents the model from memorising exact pixels and forces it to learn actual features.\n",
    "\n",
    "**We only augment the training set. Validation and test sets stay unchanged.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training augmentation (artificial variety)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,           # Pixel values: 0-255 → 0-1\n",
    "    horizontal_flip=True,     # Mirror image left-right\n",
    "    zoom_range=0.15,          # Zoom in/out slightly\n",
    "    rotation_range=15,        # Rotate up to 15 degrees\n",
    "    width_shift_range=0.1,    # Shift left/right\n",
    "    height_shift_range=0.1,   # Shift up/down\n",
    "    validation_split=0.2      # Reserve 20% for validation\n",
    ")\n",
    "\n",
    "# Validation: only rescale, no augmentation\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f'Class mapping: {train_gen.class_indices}')\n",
    "print(f'Train batches : {len(train_gen)}')\n",
    "print(f'Val batches   : {len(val_gen)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise what augmentation looks like on one image\n",
    "aug_gen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Load one sample image\n",
    "sample_cls = 'cats' if os.path.exists(os.path.join(TRAIN_DIR, 'cats')) else 'cat'\n",
    "sample_dir = os.path.join(TRAIN_DIR, sample_cls)\n",
    "sample_file = os.path.join(sample_dir, os.listdir(sample_dir)[0])\n",
    "sample_img  = img_to_array(load_img(sample_file, target_size=(224, 224)))\n",
    "sample_img  = sample_img.reshape((1,) + sample_img.shape)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes[0, 0].imshow(load_img(sample_file, target_size=(224, 224)))\n",
    "axes[0, 0].set_title('Original', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "aug_iter = aug_gen.flow(sample_img, batch_size=1)\n",
    "for i, ax in enumerate(axes.flatten()[1:]):\n",
    "    batch = next(aug_iter)\n",
    "    ax.imshow(batch[0].astype('uint8'))\n",
    "    ax.set_title(f'Augmented {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation — Same Image, Different Views for Training', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build the Model — MobileNetV2 + Custom Head\n",
    "\n",
    "We split the model into two parts:\n",
    "\n",
    "**Part 1 — Base (Frozen):** The pretrained MobileNetV2. We freeze its weights so it doesn't forget what it already knows about images.\n",
    "\n",
    "**Part 2 — Head (Trainable):** Our new layers that learn to classify dogs vs cats.\n",
    "\n",
    "```\n",
    "Input Image (224×224×3)\n",
    "        ↓\n",
    "MobileNetV2 base (FROZEN — pretrained on ImageNet)\n",
    "        ↓\n",
    "GlobalAveragePooling2D  ← squashes feature maps to a vector\n",
    "        ↓\n",
    "Dense(128, ReLU) + BatchNorm + Dropout(0.3)\n",
    "        ↓\n",
    "Dense(1, Sigmoid)  ← outputs probability: 0=Cat, 1=Dog\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Load MobileNetV2 pretrained on ImageNet, remove top classifier\n",
    "    base = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,       # Remove the ImageNet output layer\n",
    "        weights='imagenet'       # Use pretrained weights\n",
    "    )\n",
    "    base.trainable = False       # Freeze: don't update pretrained weights yet\n",
    "\n",
    "    # Build our classification head on top\n",
    "    inputs  = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x       = base(inputs, training=False)           # Run through base\n",
    "    x       = layers.GlobalAveragePooling2D()(x)     # Flatten feature maps\n",
    "    x       = layers.Dense(128, activation='relu')(x)\n",
    "    x       = layers.BatchNormalization()(x)\n",
    "    x       = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # Binary output\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    return model, base\n",
    "\n",
    "\n",
    "model, base_model = build_model()\n",
    "\n",
    "# Summary — only show our new layers (base has 154 layers inside)\n",
    "print(f'Total layers        : {len(model.layers)}')\n",
    "print(f'Trainable params    : {model.count_params()[\"trainable_params\"]:,}')\n",
    "print(f'Non-trainable params: {model.count_params()[\"non_trainable_params\"]:,}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Phase 1 — Train the Head (Base Frozen)\n",
    "\n",
    "First we only train our new dense layers. The MobileNetV2 base stays frozen.\n",
    "\n",
    "**Why?** If we updated all layers at once with a big learning rate, we would destroy the carefully learned ImageNet features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks — automatic helpers during training\n",
    "callbacks_phase1 = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc', patience=3,\n",
    "        restore_best_weights=True, mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5,\n",
    "        patience=2, min_lr=1e-6, verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print('Phase 1: Training classification head (base frozen)...')\n",
    "history1 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS_1,\n",
    "    callbacks=callbacks_phase1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Phase 2 — Fine-Tuning (Unfreeze Top Layers)\n",
    "\n",
    "Now we unfreeze the **last 30 layers** of MobileNetV2 and continue training with a very small learning rate.\n",
    "\n",
    "**Why a small LR?** We don't want to destroy learned features — we just want to slightly nudge the base model to better fit our specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last 30 layers of the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "trainable_count = sum(1 for l in base_model.layers if l.trainable)\n",
    "print(f'Unfrozen layers in base: {trainable_count} / {len(base_model.layers)}')\n",
    "\n",
    "# Recompile with a much smaller learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "callbacks_phase2 = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_auc', patience=3,\n",
    "        restore_best_weights=True, mode='max', verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.3,\n",
    "        patience=2, min_lr=1e-8, verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print('\\nPhase 2: Fine-tuning top layers of MobileNetV2...')\n",
    "history2 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS_2,\n",
    "    callbacks=callbacks_phase2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training Curves — What Happened During Training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_histories(h1, h2):\n",
    "    merged = {}\n",
    "    for key in h1.history:\n",
    "        merged[key] = h1.history[key] + h2.history.get(key, [])\n",
    "    return merged\n",
    "\n",
    "hist = merge_histories(history1, history2)\n",
    "phase1_end = len(history1.history['loss'])\n",
    "total_epochs = len(hist['loss'])\n",
    "ep = range(1, total_epochs + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, metric, ylabel in zip(\n",
    "    axes,\n",
    "    [('loss','val_loss'), ('accuracy','val_accuracy'), ('auc','val_auc')],\n",
    "    ['Loss', 'Accuracy', 'ROC-AUC']\n",
    "):\n",
    "    train_key, val_key = metric\n",
    "    ax.plot(ep, hist[train_key], 'o-', color='#3498db', lw=2, markersize=5, label='Train')\n",
    "    ax.plot(ep, hist[val_key],   'o-', color='#e74c3c', lw=2, markersize=5, label='Validation')\n",
    "\n",
    "    # Mark phase boundary\n",
    "    ax.axvline(phase1_end + 0.5, color='black', linestyle='--', lw=1.2, alpha=0.6)\n",
    "    ax.text(phase1_end * 0.5, ax.get_ylim()[0],\n",
    "            'Phase 1\\n(Frozen)', ha='center', fontsize=8, alpha=0.7)\n",
    "    ax.text(phase1_end + (total_epochs - phase1_end) * 0.5, ax.get_ylim()[0],\n",
    "            'Phase 2\\n(Fine-tune)', ha='center', fontsize=8, alpha=0.7)\n",
    "\n",
    "    ax.set_title(f'{ylabel} over Epochs')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Training History — Phase 1 (Frozen) + Phase 2 (Fine-tuning)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best val accuracy : {max(hist[\"val_accuracy\"]):.4f}')\n",
    "print(f'Best val AUC      : {max(hist[\"val_auc\"]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on entire validation set\n",
    "val_gen.reset()\n",
    "y_prob = model.predict(val_gen, verbose=1).flatten()\n",
    "y_true = val_gen.classes\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "class_names = list(val_gen.class_indices.keys())\n",
    "\n",
    "print('\\nClassification Report')\n",
    "print('=' * 50)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_true, y_prob):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix — Where Does the Model Make Mistakes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Raw counts\n",
    "im = axes[0].imshow(cm, cmap='Blues')\n",
    "axes[0].set_xticks([0,1]); axes[0].set_xticklabels(class_names)\n",
    "axes[0].set_yticks([0,1]); axes[0].set_yticklabels(class_names)\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (counts)')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[0].text(j, i, cm[i,j], ha='center', va='center',\n",
    "                     fontsize=20, fontweight='bold',\n",
    "                     color='white' if cm[i,j] > cm.max()/2 else 'black')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Normalised percentages\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "im2 = axes[1].imshow(cm_norm, cmap='Greens', vmin=0, vmax=1)\n",
    "axes[1].set_xticks([0,1]); axes[1].set_xticklabels(class_names)\n",
    "axes[1].set_yticks([0,1]); axes[1].set_yticklabels(class_names)\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title('Confusion Matrix (normalised)')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(j, i, f'{cm_norm[i,j]:.2%}', ha='center', va='center',\n",
    "                     fontsize=16, fontweight='bold',\n",
    "                     color='white' if cm_norm[i,j] > 0.5 else 'black')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.suptitle('How Well Does the Model Classify?', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'True Positives  (Dog predicted as Dog)  : {tp}')\n",
    "print(f'True Negatives  (Cat predicted as Cat)  : {tn}')\n",
    "print(f'False Positives (Cat predicted as Dog)  : {fp}')\n",
    "print(f'False Negatives (Dog predicted as Cat)  : {fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. ROC Curve — Visualising Model Discrimination\n",
    "\n",
    "The ROC curve shows the tradeoff between **catching positives (sensitivity)** and **avoiding false alarms (specificity)**. A perfect model reaches the top-left corner. The area under the curve (AUC) should be as close to 1.0 as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Find optimal threshold (Youden's J statistic)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# ROC Curve\n",
    "axes[0].plot(fpr, tpr, color='#3498db', lw=2.5, label=f'MobileNetV2 (AUC = {auc_score:.4f})')\n",
    "axes[0].plot([0,1], [0,1], 'k--', lw=1.2, label='Random Classifier (AUC = 0.5)')\n",
    "axes[0].scatter(fpr[optimal_idx], tpr[optimal_idx],\n",
    "                color='red', s=120, zorder=5,\n",
    "                label=f'Best Threshold = {optimal_threshold:.2f}')\n",
    "axes[0].set_xlabel('False Positive Rate (1 - Specificity)')\n",
    "axes[0].set_ylabel('True Positive Rate (Sensitivity)')\n",
    "axes[0].set_title('ROC Curve')\n",
    "axes[0].legend()\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1, color='#3498db')\n",
    "\n",
    "# Prediction probability distribution\n",
    "cats_mask = y_true == 0\n",
    "dogs_mask = y_true == 1\n",
    "axes[1].hist(y_prob[cats_mask], bins=40, alpha=0.6, color='#e74c3c',\n",
    "             label='Cats (actual)', density=True)\n",
    "axes[1].hist(y_prob[dogs_mask], bins=40, alpha=0.6, color='#3498db',\n",
    "             label='Dogs (actual)', density=True)\n",
    "axes[1].axvline(0.5, color='black', ls='--', lw=1.5, label='Default threshold (0.5)')\n",
    "axes[1].axvline(optimal_threshold, color='green', ls='--', lw=1.5,\n",
    "                label=f'Optimal threshold ({optimal_threshold:.2f})')\n",
    "axes[1].set_xlabel('Predicted Probability (Dog)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Prediction Score Distribution')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Correct and Wrong Predictions — Visual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(val_gen, y_true, y_pred, y_prob, class_names,\n",
    "                     correct=True, n=8):\n",
    "    val_gen.reset()\n",
    "    all_imgs, all_labels = [], []\n",
    "    for imgs, labels in val_gen:\n",
    "        all_imgs.append(imgs)\n",
    "        all_labels.extend(labels)\n",
    "        if len(all_labels) >= len(y_true): break\n",
    "    all_imgs = np.concatenate(all_imgs, axis=0)[:len(y_true)]\n",
    "\n",
    "    mask = (y_pred == y_true) if correct else (y_pred != y_true)\n",
    "    indices = np.where(mask)[0]\n",
    "    if len(indices) == 0:\n",
    "        print('No samples found.')\n",
    "        return\n",
    "    indices = np.random.choice(indices, min(n, len(indices)), replace=False)\n",
    "\n",
    "    cols = min(n, 8)\n",
    "    fig, axes = plt.subplots(1, cols, figsize=(cols * 2.2, 3))\n",
    "    if cols == 1: axes = [axes]\n",
    "\n",
    "    for ax, idx in zip(axes, indices):\n",
    "        ax.imshow(all_imgs[idx])\n",
    "        ax.axis('off')\n",
    "        prob = y_prob[idx]\n",
    "        pred_lbl = class_names[y_pred[idx]]\n",
    "        true_lbl = class_names[y_true[idx]]\n",
    "        color = '#2ecc71' if correct else '#e74c3c'\n",
    "        ax.set_title(f'Pred: {pred_lbl}\\nTrue: {true_lbl}\\n{prob:.2f}',\n",
    "                     fontsize=8, color=color)\n",
    "\n",
    "    title = 'Correct Predictions' if correct else 'Wrong Predictions (Mistakes)'\n",
    "    plt.suptitle(title, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Correctly classified samples:')\n",
    "show_predictions(val_gen, y_true, y_pred, y_prob, class_names, correct=True)\n",
    "\n",
    "print('\\nMisclassified samples (where model was wrong):')\n",
    "show_predictions(val_gen, y_true, y_pred, y_prob, class_names, correct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Confidence Analysis — Is the Model Sure or Guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = np.abs(y_prob - 0.5) * 2  # 0=uncertain, 1=very confident\n",
    "correct_mask = y_pred == y_true\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Confidence distribution — correct vs wrong\n",
    "axes[0].hist(confidence[correct_mask],   bins=30, alpha=0.7,\n",
    "             color='#2ecc71', label='Correct', density=True)\n",
    "axes[0].hist(confidence[~correct_mask],  bins=30, alpha=0.7,\n",
    "             color='#e74c3c', label='Wrong',   density=True)\n",
    "axes[0].set_xlabel('Confidence Score')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Confidence: Correct vs Wrong Predictions\\n'\n",
    "                  'Correct preds should be more confident')\n",
    "axes[0].legend()\n",
    "\n",
    "# Confidence bins — accuracy per bucket\n",
    "bins = np.linspace(0, 1, 11)\n",
    "bin_labels, bin_accs = [], []\n",
    "for i in range(len(bins)-1):\n",
    "    mask = (confidence >= bins[i]) & (confidence < bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        bin_labels.append(f'{bins[i]:.1f}-{bins[i+1]:.1f}')\n",
    "        bin_accs.append(correct_mask[mask].mean())\n",
    "\n",
    "bar_colors = ['#2ecc71' if a >= 0.8 else '#e67e22' if a >= 0.6 else '#e74c3c' for a in bin_accs]\n",
    "axes[1].bar(bin_labels, bin_accs, color=bar_colors, edgecolor='black')\n",
    "axes[1].axhline(0.5, color='black', ls='--', lw=1, label='Random chance')\n",
    "axes[1].set_xlabel('Confidence Bucket')\n",
    "axes[1].set_ylabel('Accuracy in Bucket')\n",
    "axes[1].set_title('Accuracy vs Confidence Level\\n'\n",
    "                  'Higher confidence should mean higher accuracy')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].legend()\n",
    "\n",
    "# Prediction counts per bucket\n",
    "bucket_counts = []\n",
    "for i in range(len(bins)-1):\n",
    "    mask = (confidence >= bins[i]) & (confidence < bins[i+1])\n",
    "    bucket_counts.append(mask.sum())\n",
    "axes[2].bar(bin_labels, bucket_counts, color='#3498db', edgecolor='black')\n",
    "axes[2].set_xlabel('Confidence Bucket')\n",
    "axes[2].set_ylabel('Number of Predictions')\n",
    "axes[2].set_title('How Many Predictions in Each Confidence Range?')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Avg confidence on correct predictions : {confidence[correct_mask].mean():.4f}')\n",
    "print(f'Avg confidence on wrong predictions   : {confidence[~correct_mask].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Final Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy' : accuracy_score(y_true, y_pred),\n",
    "    'Precision': precision_score(y_true, y_pred),\n",
    "    'Recall'   : recall_score(y_true, y_pred),\n",
    "    'F1 Score' : f1_score(y_true, y_pred),\n",
    "    'ROC-AUC'  : roc_auc_score(y_true, y_prob)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "names  = list(metrics.keys())\n",
    "values = list(metrics.values())\n",
    "colors = ['#2ecc71' if v >= 0.9 else '#3498db' if v >= 0.8 else '#e67e22' for v in values]\n",
    "\n",
    "bars = ax.bar(names, values, color=colors, edgecolor='black', width=0.5)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.axhline(0.9, color='green', ls='--', lw=1, alpha=0.5, label='90% line')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Final Model Performance — MobileNetV2 Dogs vs Cats')\n",
    "ax.legend()\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2,\n",
    "            bar.get_height() + 0.01,\n",
    "            f'{val:.4f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nFinal Metrics:')\n",
    "for k, v in metrics.items():\n",
    "    print(f'  {k:12s}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Predict on a Single New Image\n",
    "\n",
    "How to use the trained model on any new photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, img_path, class_names, img_size=224):\n",
    "    img  = load_img(img_path, target_size=(img_size, img_size))\n",
    "    arr  = img_to_array(img) / 255.0\n",
    "    inp  = np.expand_dims(arr, axis=0)\n",
    "    prob = model.predict(inp, verbose=0)[0][0]\n",
    "\n",
    "    pred_class = class_names[int(prob >= 0.5)]\n",
    "    confidence = prob if prob >= 0.5 else 1 - prob\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    color = '#3498db' if pred_class == 'dogs' else '#e74c3c'\n",
    "    ax.set_title(\n",
    "        f'Prediction: {pred_class.upper()}\\n'\n",
    "        f'Confidence: {confidence:.2%}\\n'\n",
    "        f'Raw probability (Dog): {prob:.4f}',\n",
    "        fontsize=11, color=color, fontweight='bold'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return pred_class, confidence\n",
    "\n",
    "# Demo with a sample from validation set\n",
    "sample_cls_name = class_names[0]\n",
    "sample_cls_dir  = os.path.join(TRAIN_DIR, sample_cls_name)\n",
    "if not os.path.exists(sample_cls_dir):\n",
    "    sample_cls_name = list(val_gen.class_indices.keys())[0]\n",
    "    sample_cls_dir  = os.path.join(TRAIN_DIR, sample_cls_name)\n",
    "\n",
    "demo_file = os.path.join(sample_cls_dir, os.listdir(sample_cls_dir)[10])\n",
    "pred, conf = predict_single_image(model, demo_file, class_names)\n",
    "print(f'Predicted: {pred} | Confidence: {conf:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A binary image classifier using MobileNetV2 Transfer Learning that classifies dog and cat photos with high accuracy — trained in minutes instead of hours.\n",
    "\n",
    "### Transfer Learning — Two Phase Strategy\n",
    "\n",
    "| Phase | What We Did | Why |\n",
    "|---|---|---|\n",
    "| Phase 1 | Froze base, trained head only | Protect pretrained features |\n",
    "| Phase 2 | Unfroze last 30 layers, tiny LR | Adapt features to our data |\n",
    "\n",
    "### Important Concepts Recap\n",
    "\n",
    "| Concept | What it means |\n",
    "|---|---|\n",
    "| Transfer Learning | Reuse features from a model trained on millions of images |\n",
    "| Data Augmentation | Artificially increase training variety — prevents overfitting |\n",
    "| Global Average Pooling | Converts spatial feature maps to a flat vector |\n",
    "| Sigmoid output | Converts raw score to probability between 0 and 1 |\n",
    "| Fine-tuning | Slightly updating pretrained layers with a very small LR |\n",
    "| ROC-AUC | Measures discrimination ability — 1.0 = perfect, 0.5 = random |\n",
    "\n",
    "### Tips for Better Results\n",
    "\n",
    "- Use more data — the more images, the better the model\n",
    "- Try EfficientNetB0 or B2 for better accuracy at moderate size\n",
    "- Increase fine-tuning epochs carefully — monitor for overfitting\n",
    "- Use learning rate warmup for more stable fine-tuning\n",
    "- Consider test-time augmentation (TTA) for a small extra accuracy boost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
